{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import glob\n",
    "import logging\n",
    "import multiprocessing\n",
    "import os\n",
    "import pprint\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import gensim.models.word2vec as w2v\n",
    "import sklearn.manifold\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_filename = '../data/testEmojis.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = open(corpus_filename).read().splitlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_corpus(corpus):\n",
    "    tokens = [x.split() for x in corpus]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onlyEmojiSequences(tokens):\n",
    "    threshold_emojis = [x for x in tokens if len(x) > 1]\n",
    "    return threshold_emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_corpus = tokenize_corpus(corpus)\n",
    "emojiSequences = onlyEmojiSequences(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The book corpus contains 292,320 tokens\n"
     ]
    }
   ],
   "source": [
    "token_count = sum([len(sentence) for sentence in emojiSequences])\n",
    "print(\"The book corpus contains {0:,} tokens\".format(token_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionality of the resulting word vectors.\n",
    "num_features = 300\n",
    "\n",
    "# Minimum word count threshold.\n",
    "min_word_count = 3\n",
    "\n",
    "# Number of threads to run in parallel.\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "\n",
    "# Context window length.\n",
    "context_size = 2\n",
    "\n",
    "# Downsample setting for frequent words.\n",
    "downsampling = 1e-3\n",
    "\n",
    "# Seed for the RNG, to make the results reproducible.\n",
    "seed = 1\n",
    "\n",
    "# think of how to set those variables so that variables from different tweets are not learned from together!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "thrones2vec = w2v.Word2Vec(\n",
    "    sg=1,\n",
    "    seed=seed,\n",
    "    workers=num_workers,\n",
    "    size=num_features,\n",
    "    min_count=min_word_count,\n",
    "    window=context_size,\n",
    "    sample=downsampling\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-10 14:12:41,317 : INFO : collecting all words and their counts\n",
      "2019-01-10 14:12:41,317 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-01-10 14:12:41,324 : INFO : PROGRESS: at sentence #10000, processed 35000 words, keeping 7 word types\n",
      "2019-01-10 14:12:41,330 : INFO : PROGRESS: at sentence #20000, processed 70000 words, keeping 7 word types\n",
      "2019-01-10 14:12:41,337 : INFO : PROGRESS: at sentence #30000, processed 105000 words, keeping 7 word types\n",
      "2019-01-10 14:12:41,346 : INFO : PROGRESS: at sentence #40000, processed 140000 words, keeping 7 word types\n",
      "2019-01-10 14:12:41,354 : INFO : PROGRESS: at sentence #50000, processed 175000 words, keeping 7 word types\n",
      "2019-01-10 14:12:41,361 : INFO : PROGRESS: at sentence #60000, processed 210000 words, keeping 7 word types\n",
      "2019-01-10 14:12:41,370 : INFO : PROGRESS: at sentence #70000, processed 245000 words, keeping 7 word types\n",
      "2019-01-10 14:12:41,379 : INFO : PROGRESS: at sentence #80000, processed 280000 words, keeping 7 word types\n",
      "2019-01-10 14:12:41,383 : INFO : collected 7 word types from a corpus of 292320 raw words and 83520 sentences\n",
      "2019-01-10 14:12:41,384 : INFO : Loading a fresh vocabulary\n",
      "2019-01-10 14:12:41,385 : INFO : effective_min_count=3 retains 7 unique words (100% of original 7, drops 0)\n",
      "2019-01-10 14:12:41,387 : INFO : effective_min_count=3 leaves 292320 word corpus (100% of original 292320, drops 0)\n",
      "2019-01-10 14:12:41,388 : INFO : deleting the raw counts dictionary of 7 items\n",
      "2019-01-10 14:12:41,389 : INFO : sample=0.001 downsamples 7 most-common words\n",
      "2019-01-10 14:12:41,390 : INFO : downsampling leaves estimated 26503 word corpus (9.1% of prior 292320)\n",
      "2019-01-10 14:12:41,391 : INFO : estimated required memory for 7 words and 300 dimensions: 20300 bytes\n",
      "2019-01-10 14:12:41,392 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "thrones2vec.build_vocab(emojiSequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec vocabulary length: 7\n"
     ]
    }
   ],
   "source": [
    "print(\"Word2Vec vocabulary length:\", len(thrones2vec.wv.vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'üò≥': <gensim.models.keyedvectors.Vocab at 0x1a1bc7b1d0>,\n",
       " 'üò¢': <gensim.models.keyedvectors.Vocab at 0x1a1cad9438>,\n",
       " 'üôÅ': <gensim.models.keyedvectors.Vocab at 0x1a1cad9358>,\n",
       " 'ü§î': <gensim.models.keyedvectors.Vocab at 0x1a1cad9550>,\n",
       " 'üòò': <gensim.models.keyedvectors.Vocab at 0x1a1cad9390>,\n",
       " 'üòç': <gensim.models.keyedvectors.Vocab at 0x1a1cad93c8>,\n",
       " '‚ù§Ô∏è': <gensim.models.keyedvectors.Vocab at 0x1a1cad9470>}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thrones2vec.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-10 14:12:42,746 : INFO : training model with 8 workers on 7 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=5 window=2\n",
      "2019-01-10 14:12:42,835 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-01-10 14:12:42,840 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-01-10 14:12:42,841 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-01-10 14:12:42,842 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-01-10 14:12:42,842 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-01-10 14:12:42,842 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-10 14:12:42,843 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-10 14:12:42,843 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-10 14:12:42,843 : INFO : EPOCH - 1 : training on 292320 raw words (26312 effective words) took 0.1s, 326814 effective words/s\n",
      "2019-01-10 14:12:42,844 : INFO : training on a 292320 raw words (26312 effective words) took 0.1s, 270208 effective words/s\n",
      "2019-01-10 14:12:42,844 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(26312, 292320)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thrones2vec.train(emojiSequences, total_examples=thrones2vec.corpus_count, epochs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"trained\"):\n",
    "    os.makedirs(\"trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-10 14:15:18,635 : INFO : saving Word2Vec object under trained/mostSimilarWorkButSimilarityComparisonDoesnt.w2v, separately None\n",
      "2019-01-10 14:15:18,636 : INFO : not storing attribute vectors_norm\n",
      "2019-01-10 14:15:18,636 : INFO : not storing attribute cum_table\n",
      "2019-01-10 14:15:18,638 : INFO : saved trained/mostSimilarWorkButSimilarityComparisonDoesnt.w2v\n"
     ]
    }
   ],
   "source": [
    "thrones2vec.save(os.path.join(\"trained\", \"mostSimilarWorkButSimilarityComparisonDoesnt.w2v\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# explore the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-10 14:12:44,647 : INFO : loading Word2Vec object from trained/testEmoji.w2v\n",
      "2019-01-10 14:12:44,648 : INFO : loading wv recursively from trained/testEmoji.w2v.wv.* with mmap=None\n",
      "2019-01-10 14:12:44,649 : INFO : setting ignored attribute vectors_norm to None\n",
      "2019-01-10 14:12:44,649 : INFO : loading vocabulary recursively from trained/testEmoji.w2v.vocabulary.* with mmap=None\n",
      "2019-01-10 14:12:44,650 : INFO : loading trainables recursively from trained/testEmoji.w2v.trainables.* with mmap=None\n",
      "2019-01-10 14:12:44,651 : INFO : setting ignored attribute cum_table to None\n",
      "2019-01-10 14:12:44,651 : INFO : loaded trained/testEmoji.w2v\n"
     ]
    }
   ],
   "source": [
    "thrones2vec = w2v.Word2Vec.load(os.path.join(\"trained\", \"testEmoji.w2v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector1 = thrones2vec.wv['üò≥']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector2 = thrones2vec.wv['üòç']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector3 = thrones2vec.wv['‚ù§Ô∏è']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thrones2vec.wv.similarity('üò≥', 'üò≥')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'üò≥': <gensim.models.keyedvectors.Vocab at 0x1a1cad9cf8>,\n",
       " 'üò¢': <gensim.models.keyedvectors.Vocab at 0x1a1cad9e10>,\n",
       " 'üôÅ': <gensim.models.keyedvectors.Vocab at 0x1a1cad9e48>,\n",
       " 'ü§î': <gensim.models.keyedvectors.Vocab at 0x1a1cad9e80>,\n",
       " 'üòò': <gensim.models.keyedvectors.Vocab at 0x1a1cad9eb8>,\n",
       " 'üòç': <gensim.models.keyedvectors.Vocab at 0x1a1cad9ef0>,\n",
       " '‚ù§Ô∏è': <gensim.models.keyedvectors.Vocab at 0x1a1cad9f28>}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thrones2vec.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('üòò', 0.9771696925163269),\n",
       " ('‚ù§Ô∏è', 0.9631988406181335),\n",
       " ('üò¢', 0.1335771232843399),\n",
       " ('üôÅ', 0.11866120994091034),\n",
       " ('üò≥', 0.10258054733276367),\n",
       " ('ü§î', 0.09710533171892166)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thrones2vec.wv.most_similar('üòç')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "similarity = thrones2vec.wv.similarity('üòç', '‚ù§Ô∏è')\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-10 10:54:06,970 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cereal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "print(word_vectors.doesnt_match(\"breakfast cereal dinner lunch\".split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = word_vectors.most_similar_cosmul(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queen: 0.8965\n"
     ]
    }
   ],
   "source": [
    "print(\"{}: {:.4f}\".format(*result[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = word_vectors.most_similar_cosmul(positive=['paris', 'germany'], negative=['france'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
