{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as A\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "import sklearn.manifold \n",
    "from matplotlib import pyplot as plt\n",
    "import re\n",
    "import codecs\n",
    "from numpy  import array\n",
    "from scipy import stats\n",
    "# from scipy.spatial import distance\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_filename = '../data/extracted_emoji_sequences.txt' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = open(corpus_filename).read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_corpus(corpus):\n",
    "    tokens = [x.split() for x in corpus]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onlyEmojiSequences(tokens):\n",
    "    threshold_emojis = [x for x in tokens if len(x) > 1]\n",
    "    return threshold_emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_corpus = tokenize_corpus(corpus)\n",
    "emojiSequences = onlyEmojiSequences(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = []\n",
    "for sentence in tokenized_corpus:\n",
    "    for token in sentence:\n",
    "        if token not in vocabulary:\n",
    "            vocabulary.append(token)\n",
    "\n",
    "word2idx = {w: idx for (idx, w) in enumerate(vocabulary)}\n",
    "idx2word = {idx: w for (idx, w) in enumerate(vocabulary)}\n",
    "\n",
    "vocabulary_size = len(vocabulary)\n",
    "\n",
    "# this is just the very basic translation both ways plus the length of vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 8\n",
    "idx_pairs = []\n",
    "# for each sentence\n",
    "for sentence in tokenized_corpus:\n",
    "    indices = [word2idx[word] for word in sentence]\n",
    "    # for each word, threated as center word\n",
    "    for center_word_pos in range(len(indices)):\n",
    "        # for each window position\n",
    "        for w in range(-window_size, window_size + 1):\n",
    "            context_word_pos = center_word_pos + w\n",
    "            # make soure not jump out sentence\n",
    "            if context_word_pos < 0 or context_word_pos >= len(indices) or center_word_pos == context_word_pos:\n",
    "                continue\n",
    "            context_word_idx = indices[context_word_pos]\n",
    "            idx_pairs.append((indices[center_word_pos], context_word_idx))\n",
    "\n",
    "idx_pairs = np.array(idx_pairs) # it will be useful to have this as numpy array\n",
    "\n",
    "# sole purpose of this is to have pairs! of target and context word\n",
    "# super simple once you have figured out the code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.\n"
     ]
    }
   ],
   "source": [
    "testWriter = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadedDataSet(Dataset):\n",
    "\n",
    "    def __init__(self, pairs):\n",
    "        self.data = pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        context, target = self.data[idx]\n",
    "        return context, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_layer(indexes):\n",
    "    x = torch.zeros(vocabulary_size, len(indexes)).float()\n",
    "    for column in range(len(indexes)):\n",
    "        for i in indexes:\n",
    "            x[i][column] = 1.0\n",
    "            return x\n",
    "\n",
    "# this is a one hot encoded something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9742/9742 [00:50<00:00, 192.49it/s, loss=7.49]\n",
      "100%|██████████| 9742/9742 [00:56<00:00, 172.06it/s, loss=6.95]\n",
      " 87%|████████▋ | 8429/9742 [00:50<00:07, 165.31it/s, loss=7.04]"
     ]
    }
   ],
   "source": [
    "dimensionSize = 40\n",
    "num_epochs = 20\n",
    "lr = 0.001\n",
    "batchSize = 150\n",
    "\n",
    "inputLayer = torch.randn(dimensionSize, vocabulary_size, requires_grad=True)\n",
    "outputLayer = torch.randn(vocabulary_size, dimensionSize, requires_grad=True)\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam([inputLayer, outputLayer], lr)\n",
    "\n",
    "# print('total amount of batches {}'.format(len(idx_pairs) / batchSize))\n",
    "for epo in range(num_epochs):\n",
    "    priorLoss = 0\n",
    "    \n",
    "    dataset = LoadedDataSet(idx_pairs)\n",
    "    loader = DataLoader(dataset, batchSize, shuffle=True)\n",
    "    \n",
    "    pbar = tqdm(loader)\n",
    "#     pbar.set_description(\"[Epoch {}]\".format(epo))\n",
    "\n",
    "    for data, target in pbar:\n",
    "        # one hot encoded tensor\n",
    "        x = get_input_layer(data)\n",
    "\n",
    "        # target word \n",
    "        y_true = target    \n",
    "\n",
    "        # Hidden Layer: gradient magic happening ...\n",
    "        z1 = torch.matmul(inputLayer, x)\n",
    "        z2 = torch.matmul(outputLayer, z1)\n",
    "\n",
    "        output = loss(torch.t(z2), y_true)  \n",
    "        testWriter.add_scalar('lossvalue', output, epo)\n",
    "\n",
    "\n",
    "#         priorLoss += output.item() \n",
    "        output.backward()\n",
    "\n",
    "        optimizer.step()       \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pbar.set_postfix(loss=output.item())\n",
    "        \n",
    "#     print(priorLoss)\n",
    "    \n",
    "    \n",
    "testwriter.export_scalars_to_json(\"./all_scalars.json\")\n",
    "testWriter.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"SOFTMAX_trained\"):\n",
    "    os.makedirs(\"SOFTMAX_trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(outputLayer, os.path.join(\"SOFTMAX_trained\", \"test#2.w2v\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATING TRAINED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadedLayer = torch.load(os.path.join(\"SOFTMAX_trained\", \"test#2.w2v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracts the 508 Annotator Results as the Gold-Standard\n",
    "corpus_filename = '../data/EmoSim508.json'\n",
    "corpus = open(corpus_filename).read()\n",
    "annotator_similarity_score_508 = list(array(re.findall('(?<=_Annotator_Agreement\": )(.*?)(?=\\})', corpus)))\n",
    "\n",
    "# extract Wijeratne's Cosine_Similarities of the model which was trained on Google_Sense_Labels\n",
    "google_sense_labels_score_508 = list(array(re.findall('(?<=Google_Sense_Label\": )(.*?)(?=\\,)', corpus)))\n",
    "\n",
    "# glyph_pairs_1016\n",
    "unicode_pairs_1016 = re.findall('(?<=unicodelong\": \"\\\\\\)(.*?)(?=\")', corpus)    \n",
    "glyph_pairs_1016 = [codecs.decode(unicode_pairs_1016[x].replace(str('\\\\\\\\'),str('\\\\')).replace('_',''), 'unicode_escape') for x in range(len(unicode_pairs_1016))]\n",
    "\n",
    "# computation of Cosine Similarity\n",
    "goldstandard = []\n",
    "selftrained = []\n",
    "google_sense_labels = []\n",
    "for x in range(len(annotator_similarity_score_508)):\n",
    "    cosineSimilarity = None\n",
    "    \n",
    "    emoji1 = glyph_pairs_1016.pop(0)\n",
    "    emoji2 = glyph_pairs_1016.pop(0)\n",
    "    \n",
    "    try:\n",
    "        cosineSimilarity = cosine_similarity(loadedLayer.detach().cpu().numpy()[word2idx[emoji1]].reshape(-1,dimensionSize), loadedLayer.detach().cpu().numpy()[word2idx[emoji2]].reshape(-1,dimensionSize))[0][0]\n",
    "    except:\n",
    "        print('the cosine similarity between ' + emoji1 + ' and ' + emoji2 + ' could not be computed.')\n",
    "    \n",
    "    if(cosineSimilarity is not None):\n",
    "        goldstandard.append(annotator_similarity_score_508.pop(0))\n",
    "        selftrained.append(cosineSimilarity)\n",
    "        google_sense_labels.append(float(google_sense_labels_score_508.pop(0)))\n",
    "        \n",
    "\n",
    "# skalierter GoldStandard\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "scaled_goldstandard = min_max_scaler.fit_transform(np.asarray(goldstandard).reshape(-1, 1))\n",
    "\n",
    "print()\n",
    "\n",
    "# computation of SPEARRANK CORRELATION COEFFICIENT\n",
    "meinSPEARMAN = stats.spearmanr(goldstandard, selftrained)\n",
    "seinSPEARMAN = stats.spearmanr(goldstandard, google_sense_labels)\n",
    "print('mein Spearman: {}'.format(meinSPEARMAN.correlation))\n",
    "print('sein Spearman: {}'.format(seinSPEARMAN.correlation))\n",
    "\n",
    "\n",
    "# computation of MAE\n",
    "meinMAE = mean_absolute_error(scaled_goldstandard, min_max_scaler.fit_transform(np.asarray(selftrained).reshape(-1, 1)))\n",
    "seinMAE = mean_absolute_error(scaled_goldstandard, google_sense_labels)\n",
    "print('mein MAE ist {}'.format(meinMAE))\n",
    "print('sein MAE ist {}'.format(seinMAE))\n",
    "\n",
    "\n",
    "# computation of MSE\n",
    "meinMSE = mean_squared_error(scaled_goldstandard, min_max_scaler.fit_transform(np.asarray(selftrained).reshape(-1, 1)))\n",
    "seinMSE = mean_squared_error(scaled_goldstandard, google_sense_labels)\n",
    "print('mein MSE ist {}'.format(meinMSE))\n",
    "print('sein MSE ist {}'.format(seinMSE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
